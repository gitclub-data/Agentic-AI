{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitclub-data/Agentic-AI/blob/master/Natual_language_Query_Answers_From_Database.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing all the nessary libraries"
      ],
      "metadata": {
        "id": "SnK6X-RWUteX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install typing_extensions\n",
        "!pip install langgraph\n",
        "!pip install langchain-community\n",
        "!pip install -U \"langchain[google-genai]\""
      ],
      "metadata": {
        "id": "kEKQBV2nz6fV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connect With Google Drive"
      ],
      "metadata": {
        "id": "d2IVZIavYE3N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKQKgO1_BQG5"
      },
      "outputs": [],
      "source": [
        "#connect colab with google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Real and Dummy Dataset Real for store real data to query, dummy store very much less but good quality data for validation purposes"
      ],
      "metadata": {
        "id": "iM2u9biNY0of"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a small database to store some data\n",
        "import sqlite3\n",
        "conn = sqlite3.connect('real_database.db')\n",
        "dummy_conn = sqlite3.connect('dummy_database.db')"
      ],
      "metadata": {
        "id": "sWhjmhOOB-tQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cursor = conn.cursor()\n",
        "dummy_cursor = dummy_conn.cursor()"
      ],
      "metadata": {
        "id": "_iUKlkDL5LJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_users_table = '''\n",
        "    CREATE TABLE IF NOT EXISTS users (\n",
        "        user_id INTEGER PRIMARY KEY,\n",
        "        user_gender BOOLEAN,\n",
        "        bucketized_user_age INTEGER,\n",
        "        user_occupation_label INTEGER,\n",
        "        user_occupation_text TEXT,\n",
        "        user_zip_code INTEGER\n",
        "    )\n",
        "'''\n",
        "cursor.execute(create_users_table)\n",
        "dummy_cursor.execute(create_users_table)"
      ],
      "metadata": {
        "id": "7MW7z7UhCPIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_ratings_table = '''\n",
        "    CREATE TABLE IF NOT EXISTS ratings (\n",
        "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        movie_id INTEGER,\n",
        "        user_id INTEGER,\n",
        "        user_rating INTEGER,\n",
        "        timestamp INTEGER\n",
        "    )\n",
        "'''\n",
        "cursor.execute(create_ratings_table)\n",
        "dummy_cursor.execute(create_ratings_table)"
      ],
      "metadata": {
        "id": "ZlRlKJOZRntu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_movies_table = '''\n",
        "    CREATE TABLE IF NOT EXISTS movies (\n",
        "        movie_id INTEGER PRIMARY KEY,\n",
        "        movie_title TEXT,\n",
        "        poster_url TEXT\n",
        "    )\n",
        "'''\n",
        "cursor.execute(create_movies_table)\n",
        "dummy_cursor.execute(create_movies_table)"
      ],
      "metadata": {
        "id": "3-vDl97OSfBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MovieLens 1M with Posters & Metadata (Kaggle Dataset)"
      ],
      "metadata": {
        "id": "afI8mOUZXGTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Adjust paths if your files are in a subfolder\n",
        "ratings_df = pd.read_csv('/content/drive/MyDrive/Movies_Data/ratings.csv')\n",
        "movies_df = pd.read_csv('/content/drive/MyDrive/Movies_Data/movies.csv')\n",
        "users_df = pd.read_csv('/content/drive/MyDrive/Movies_Data/users.csv')"
      ],
      "metadata": {
        "id": "bfPR6Vm6TT0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ENTERED FULL DATA IN DUMMY DATABASE FOR NOW ONLY FOR POC PURPOSE"
      ],
      "metadata": {
        "id": "biNTVfyidO_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.to_sql('ratings', conn, if_exists='append', index=False)\n",
        "movies_df.to_sql('movies', conn, if_exists='append', index=False)\n",
        "users_df.to_sql('users', conn, if_exists='append', index=False)\n",
        "\n",
        "ratings_df.to_sql('ratings', dummy_conn, if_exists='append', index=False)\n",
        "movies_df.to_sql('movies', dummy_conn, if_exists='append', index=False)\n",
        "users_df.to_sql('users', dummy_conn, if_exists='append', index=False)\n",
        "\n",
        "dummy_conn.commit()\n",
        "dummy_conn.close()\n",
        "\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "e70NX9qSTxyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('real_database.db')\n",
        "cursor = conn.cursor()\n",
        "cursor.execute('SELECT * FROM users')\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "# Print each row\n",
        "for row in rows:\n",
        "    print(row)\n",
        "    break\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "6UT2jrsHT5R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initial table description"
      ],
      "metadata": {
        "id": "ZKV6QE1axDST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATED THIS JSON OF TABLE INFORMATION TO GET THE TABLE SCHEMA IN STRUCTURED FORMAT -> NEEDED AS INPUT SO THAT MODEL CAN EXCECTLY KNOW WHAT TYPE OF QUERY IT HAS TO GENERATE(Used Previously when not used embeddings..)"
      ],
      "metadata": {
        "id": "1ZNHFltOdbZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table_info = {\n",
        "    \"name\": \"tables_information\",\n",
        "    \"tables\": [\n",
        "        {\n",
        "            \"table_name\": \"users\",\n",
        "            \"table_description\": \"This table contains records of users who have watched the movie in the past.\",\n",
        "            \"columns\": [\n",
        "                {\n",
        "                    \"column_name\": \"user_id\",\n",
        "                    \"column_type\": \"INTEGER\",\n",
        "                    \"column_description\": \"Unique identifier for each user\"\n",
        "                },\n",
        "                {\n",
        "                    \"column_name\": \"user_gender\",\n",
        "                    \"column_type\": \"BOOLEAN\",\n",
        "                    \"column_description\": \"True = Male, False = Female\"\n",
        "                },\n",
        "                {\n",
        "                    \"column_name\": \"bucketized_user_age\",\n",
        "                    \"column_type\": \"INTEGER\",\n",
        "                    \"column_description\": (\n",
        "                        \"Age group bucket:\\n\"\n",
        "                        \"- 1: Under 18\\n\"\n",
        "                        \"- 18: 18–24\\n\"\n",
        "                        \"- 25: 25–34\\n\"\n",
        "                        \"- 35: 35–44\\n\"\n",
        "                        \"- 45: 45–49\\n\"\n",
        "                        \"- 50: 50–55\\n\"\n",
        "                        \"- 56: 56-..\"\n",
        "                    )\n",
        "                },\n",
        "                {\n",
        "                    \"column_name\": \"user_occupation_label\",\n",
        "                    \"column_type\": \"INTEGER\",\n",
        "                    \"column_description\": (\n",
        "                        \"Integer code representing occupation:\\n\"\n",
        "                        \"- 0: other or not specified\\n\"\n",
        "                        \"- 1: academic/educator\\n\"\n",
        "                        \"- 2: artist\\n\"\n",
        "                        \"- 3: clerical/admin\\n\"\n",
        "                        \"- 4: college/grad student\\n\"\n",
        "                        \"- 5: customer service\\n\"\n",
        "                        \"- 6: doctor/health care\\n\"\n",
        "                        \"- 7: executive/managerial\\n\"\n",
        "                        \"- 8: farmer\\n\"\n",
        "                        \"- 9: homemaker\\n\"\n",
        "                        \"- 10: K-12 student\\n\"\n",
        "                        \"- 11: lawyer\\n\"\n",
        "                        \"- 12: programmer\\n\"\n",
        "                        \"- 13: retired\\n\"\n",
        "                        \"- 14: sales/marketing\\n\"\n",
        "                        \"- 15: scientist\\n\"\n",
        "                        \"- 16: self-employed\\n\"\n",
        "                        \"- 17: technician/engineer\\n\"\n",
        "                        \"- 18: tradesman/craftsman\\n\"\n",
        "                        \"- 19: unemployed\\n\"\n",
        "                        \"- 20: writer\"\n",
        "                    )\n",
        "                },\n",
        "                {\n",
        "                    \"column_name\": \"user_occupation_text\",\n",
        "                    \"column_type\": \"TEXT\",\n",
        "                    \"column_description\": \"Text description of the occupation (e.g. Writer)\"\n",
        "                },\n",
        "                {\n",
        "                    \"column_name\": \"user_zip_code\",\n",
        "                    \"column_type\": \"INTEGER\",\n",
        "                    \"column_description\": \"ZIP code provided voluntarily by the user\"\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"table_name\": \"ratings\",\n",
        "            \"table_description\": \"This table captures the ratings provided by users for specific movies.\",\n",
        "            \"columns\": [\n",
        "                {\n",
        "                    \"column_name\": \"user_id\",\n",
        "                    \"column_type\": \"INTEGER\",\n",
        "                    \"column_description\": \"Foreign key referring to users table.\"\n",
        "                },\n",
        "                {\n",
        "                    \"column_name\": \"movie_id\",\n",
        "                    \"column_type\": \"INTEGER\",\n",
        "                    \"column_description\": \"Foreign key referring to movies table.\"\n",
        "                },\n",
        "                {\n",
        "                    \"column_name\": \"user_rating\",\n",
        "                    \"column_type\": \"INTEGER\",\n",
        "                    \"column_description\": \"Rating from 1 to 5 (whole stars only).\"\n",
        "                },\n",
        "                {\n",
        "                    \"column_name\": \"timestamp\",\n",
        "                    \"column_type\": \"INTEGER\",\n",
        "                    \"column_description\": \"Unix timestamp when the rating was submitted.\"\n",
        "                }\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"table_name\": \"movies\",\n",
        "            \"table_description\": \"This table includes metadata related to the movies.\",\n",
        "            \"columns\": [\n",
        "                {\n",
        "                    \"column_name\": \"movie_id\",\n",
        "                    \"column_type\": \"INTEGER\",\n",
        "                    \"column_description\": \"Unique movie identifier\"\n",
        "                },\n",
        "                {\n",
        "                    \"column_name\": \"movie_title\",\n",
        "                    \"column_type\": \"TEXT\",\n",
        "                    \"column_description\": \"Title of the movie (with release year)\"\n",
        "                },\n",
        "                {\n",
        "                    \"column_name\": \"poster_url\",\n",
        "                    \"column_type\": \"TEXT\",\n",
        "                    \"column_description\": \"Direct URL to the movie's poster image\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "MWQXwkdBiE-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plan of action: For getting table information from embeddings.."
      ],
      "metadata": {
        "id": "eMqpZkrpeLYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use faiss vector store\n",
        "# ->> type 1 -> table embedding stores whole table record (table and its column information in vector store).\n",
        "#  (used for what table we will be needing for actually getting the data)\n",
        "# ->> type 2 -> used to store the table name its column name and description of the column\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ->> getting the result by k nearest neighbour algo.. but it is impossible to determine if we got all the necessary details\n",
        "# in the first try or may be we can find that out. so we let the model check if not find all the nessary details we are going\n",
        "#  to search the table again untill reached the max limit and break out and sent can't find neccessary columns message to the output."
      ],
      "metadata": {
        "id": "HVI0a9FxecGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-community faiss-cpu sentence-transformers"
      ],
      "metadata": {
        "id": "z1_5v4V8jlnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used a Open Source Model Because I do not have that much money to get a paid subscription"
      ],
      "metadata": {
        "id": "dgz0Q7hEe0WH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "NXrAEc9HhJot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Define embedding function that LangChain expects\n",
        "embedding_function = lambda texts: model.encode(texts, convert_to_numpy=True)\n",
        "\n",
        "# Create FAISS index\n",
        "sample_embedding = model.encode(\"hello world\")\n",
        "embedding_dimension = len(sample_embedding)\n",
        "index = faiss.IndexFlatL2(embedding_dimension)\n",
        "\n",
        "# Create FAISS vector store\n",
        "vector_store = FAISS(\n",
        "    embedding_function=embedding_function,\n",
        "    index=index,\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={},\n",
        ")"
      ],
      "metadata": {
        "id": "jLZCdWSNjeVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Created Documents and saved them into vector store (column as well as tables)"
      ],
      "metadata": {
        "id": "Zdh0w3Q4fUwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#table schema\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "user_schema = Document(\n",
        "    page_content=\"\"\"\n",
        "Table Name: users\n",
        "Description: This table contains records of users who have watched the movie in the past.\n",
        "\n",
        "Columns:\n",
        "- user_id (INTEGER): Unique identifier for each user\n",
        "- user_gender (BOOLEAN): True = Male, False = Female\n",
        "- bucketized_user_age (INTEGER): Age group bucket:\n",
        "  - 1: Under 18\n",
        "  - 18: 18–24\n",
        "  - 25: 25–34\n",
        "  - 35: 35–44\n",
        "  - 45: 45–49\n",
        "  - 50: 50–55\n",
        "  - 56: 56 and above\n",
        "- user_occupation_label (INTEGER): Integer code for occupation\n",
        "  - 0: other or not specified\n",
        "  - 1–20: specific occupations like artist, lawyer, student, etc.\n",
        "- user_occupation_text (TEXT): Occupation description (e.g. Writer)\n",
        "- user_zip_code (INTEGER): ZIP code provided voluntarily by the user\n",
        "\"\"\",\n",
        "    metadata={\"source\": \"table_schema\", \"table_name\": \"users\"}\n",
        ")\n",
        "\n",
        "ratings_schema = Document(\n",
        "    page_content=\"\"\"\n",
        "Table Name: ratings\n",
        "Description: This table captures the ratings provided by users for specific movies.\n",
        "\n",
        "Columns:\n",
        "- user_id (INTEGER): Foreign key referring to users table\n",
        "- movie_id (INTEGER): Foreign key referring to movies table\n",
        "- user_rating (INTEGER): Rating from 1 to 5 (whole stars only)\n",
        "- timestamp (INTEGER): Unix timestamp when the rating was submitted\n",
        "\"\"\",\n",
        "    metadata={\"source\": \"table_schema\", \"table_name\": \"ratings\"}\n",
        ")\n",
        "\n",
        "movies_schema = Document(\n",
        "    page_content=\"\"\"\n",
        "Table Name: movies\n",
        "Description: This table includes metadata related to the movies.\n",
        "\n",
        "Columns:\n",
        "- movie_id (INTEGER): Unique movie identifier\n",
        "- movie_title (TEXT): Title of the movie (with release year)\n",
        "- poster_url (TEXT): Direct URL to the movie's poster image\n",
        "\"\"\",\n",
        "    metadata={\"source\": \"table_schema\", \"table_name\": \"movies\"}\n",
        ")"
      ],
      "metadata": {
        "id": "NRU3hMONjujx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id_doc = Document(\n",
        "    page_content=\"- user_id (INTEGER): Unique identifier for each user\",\n",
        "    metadata={\n",
        "        \"source\": \"column_schema\",\n",
        "        \"table_name\": \"users\",\n",
        "        \"table_description\": \"This table contains records of users who have watched the movie in the past.\",\n",
        "        \"column_name\": \"user_id\"\n",
        "    }\n",
        ")\n",
        "\n",
        "user_gender_doc = Document(\n",
        "    page_content=\"- user_gender (BOOLEAN): True = Male, False = Female\",\n",
        "    metadata={\n",
        "        \"source\": \"column_schema\",\n",
        "        \"table_name\": \"users\",\n",
        "        \"table_description\": \"This table contains records of users who have watched the movie in the past.\",\n",
        "        \"column_name\": \"user_gender\"\n",
        "    }\n",
        ")\n",
        "\n",
        "bucketized_user_age_doc = Document(\n",
        "    page_content=\"\"\"- bucketized_user_age (INTEGER): Age group bucket:\n",
        "  - 1: Under 18\n",
        "  - 18: 18–24\n",
        "  - 25: 25–34\n",
        "  - 35: 35–44\n",
        "  - 45: 45–49\n",
        "  - 50: 50–55\n",
        "  - 56: 56 and above\"\"\",\n",
        "    metadata={\n",
        "        \"source\": \"column_schema\",\n",
        "        \"table_name\": \"users\",\n",
        "        \"table_description\": \"This table contains records of users who have watched the movie in the past.\",\n",
        "        \"column_name\": \"bucketized_user_age\"\n",
        "    }\n",
        ")\n",
        "\n",
        "user_occupation_label_doc = Document(\n",
        "    page_content=\"\"\"- user_occupation_label (INTEGER): Integer code for occupation\n",
        "  - 0: other or not specified\n",
        "  - 1–20: specific occupations like artist, lawyer, student, etc.\"\"\",\n",
        "    metadata={\n",
        "        \"source\": \"column_schema\",\n",
        "        \"table_name\": \"users\",\n",
        "        \"table_description\": \"This table contains records of users who have watched the movie in the past.\",\n",
        "        \"column_name\": \"user_occupation_label\"\n",
        "    }\n",
        ")\n",
        "\n",
        "user_occupation_text_doc = Document(\n",
        "    page_content='- user_occupation_text (TEXT): Occupation description (e.g. Writer)',\n",
        "    metadata={\n",
        "        \"source\": \"column_schema\",\n",
        "        \"table_name\": \"users\",\n",
        "        \"table_description\": \"This table contains records of users who have watched the movie in the past.\",\n",
        "        \"column_name\": \"user_occupation_text\"\n",
        "    }\n",
        ")\n",
        "\n",
        "user_zip_code_doc = Document(\n",
        "    page_content='- user_zip_code (INTEGER): ZIP code provided voluntarily by the user',\n",
        "    metadata={\n",
        "        \"source\": \"column_schema\",\n",
        "        \"table_name\": \"users\",\n",
        "        \"table_description\": \"This table contains records of users who have watched the movie in the past.\",\n",
        "        \"column_name\": \"user_zip_code\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "OSTaFsecotWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id__doc = Document(\n",
        "    page_content=\"- user_id (INTEGER): Foreign key referring to users table\",\n",
        "    metadata={\n",
        "        \"source\": \"column_schema\",\n",
        "        \"table_name\": \"ratings\",\n",
        "        \"table_description\": \"This table captures the ratings provided by users for specific movies.\",\n",
        "        \"column_name\": \"user_id\"\n",
        "    }\n",
        ")\n",
        "\n",
        "movie_id_doc = Document(\n",
        "    page_content=\"- movie_id (INTEGER): Foreign key referring to movies table\",\n",
        "    metadata={\n",
        "        \"source\": \"column_schema\",\n",
        "        \"table_name\": \"ratings\",\n",
        "        \"table_description\": \"This table captures the ratings provided by users for specific movies.\",\n",
        "        \"column_name\": \"movie_id\"\n",
        "    }\n",
        ")\n",
        "\n",
        "user_rating_doc = Document(\n",
        "    page_content=\"- user_rating (INTEGER): Rating from 1 to 5 (whole stars only)\",\n",
        "    metadata={\n",
        "        \"source\": \"column_schema\",\n",
        "        \"table_name\": \"ratings\",\n",
        "        \"table_description\": \"This table captures the ratings provided by users for specific movies.\",\n",
        "        \"column_name\": \"user_rating\"\n",
        "    }\n",
        ")\n",
        "\n",
        "timestamp_doc = Document(\n",
        "    page_content=\"- timestamp (INTEGER): Unix timestamp when the rating was submitted\",\n",
        "    metadata={\n",
        "        \"source\": \"column_schema\",\n",
        "        \"table_name\": \"ratings\",\n",
        "        \"table_description\": \"This table captures the ratings provided by users for specific movies.\",\n",
        "        \"column_name\": \"timestamp\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "V9FZOJToqRbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_id__doc = Document(\n",
        "    page_content=\"- movie_id (INTEGER): Unique movie identifier\",\n",
        "    metadata={\n",
        "        \"source\": \"column_schema\",\n",
        "        \"table_name\": \"movies\",\n",
        "        \"table_description\": \"This table includes metadata related to the movies.\",\n",
        "        \"column_name\": \"movie_id\"\n",
        "    }\n",
        ")\n",
        "\n",
        "movie_title_doc = Document(\n",
        "    page_content=\"- movie_title (TEXT): Title of the movie (with release year)\",\n",
        "    metadata={\n",
        "        \"source\": \"column_schema\",\n",
        "        \"table_name\": \"movies\",\n",
        "        \"table_description\": \"This table includes metadata related to the movies.\",\n",
        "        \"column_name\": \"movie_title\"\n",
        "    }\n",
        ")\n",
        "\n",
        "poster_url_doc = Document(\n",
        "    page_content=\"- poster_url (TEXT): Direct URL to the movie's poster image\",\n",
        "    metadata={\n",
        "        \"source\": \"column_schema\",\n",
        "        \"table_name\": \"movies\",\n",
        "        \"table_description\": \"This table includes metadata related to the movies.\",\n",
        "        \"column_name\": \"poster_url\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "G_nbF2YXqhnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "MAX_TABLE_SCHEMA = 3\n",
        "MAX_COLUMN_SCHEMA = 13\n",
        "\n",
        "# Create Document objects (if not already)\n",
        "raw_documents = [\n",
        "    user_schema,\n",
        "    ratings_schema,\n",
        "    movies_schema,\n",
        "    user_id__doc,\n",
        "    user_gender_doc,\n",
        "    bucketized_user_age_doc,\n",
        "    user_occupation_label_doc,\n",
        "    user_occupation_text_doc,\n",
        "    user_zip_code_doc,\n",
        "    user_id_doc,\n",
        "    movie_id_doc,\n",
        "    user_rating_doc,\n",
        "    timestamp_doc,\n",
        "    movie_id__doc,\n",
        "    movie_title_doc,\n",
        "    poster_url_doc\n",
        "]\n",
        "\n",
        "# Add documents to the FAISS vector store\n",
        "vector_store.add_documents(raw_documents)"
      ],
      "metadata": {
        "id": "T8YI__RqhJsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.save_local(\"table_information\")"
      ],
      "metadata": {
        "id": "EBQmSFZJtBZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used a free tier model and you know what I needed my keys safe so i have stored in secrets 'key icon ON YOUR LEFT (for marvel-fans only)' (In colab)"
      ],
      "metadata": {
        "id": "goWIkVAmfnHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chat_models import init_chat_model\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")"
      ],
      "metadata": {
        "id": "wvz-xOfnxOV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Started Creating Our First Workflow (Related Table generation)"
      ],
      "metadata": {
        "id": "NqeAVQRzhu_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import START,END, StateGraph\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "class TableState(TypedDict):\n",
        "    question: str # user query\n",
        "    relevant_tables : int  # no of relevant tables\n",
        "    table_documents : list # tables documents which are going to fetch\n",
        "    validation_result : dict # validation result\n",
        "    resultant_tables: list # list of tables\n",
        "    error_result : str # if the relevant tables can not found.\n",
        "    vectorstore : FAISS\n",
        "\n",
        "def get_relevant_tables(state : TableState):\n",
        "  vector_store = state[\"vectorstore\"]\n",
        "  results = vector_store.similarity_search(\n",
        "    state[\"question\"],\n",
        "    k=state[\"relevant_tables\"],\n",
        "    filter={\"source\": \"table_schema\"},\n",
        "  )\n",
        "  return {\"table_documents\":results}"
      ],
      "metadata": {
        "id": "hrlOQOgIy7SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QueryJsonOutput(TypedDict):\n",
        "    \"\"\"Generated SQL query.\"\"\"\n",
        "    enough_information: Annotated[bool, ..., \"whether the available schema provides sufficient information to write a valid SQL query that could answer the question or not.\"]"
      ],
      "metadata": {
        "id": "7a__ZkBEpwMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_relevant_tables(state : TableState):\n",
        "  system_prompt = \"\"\"\n",
        "You are a helpful assistant that evaluates whether a given set of database tables contains enough schema information to generate a valid SQL query that answers a natural language question **in full**.\n",
        "\n",
        "You will be provided with:\n",
        "- A natural language question.\n",
        "- One or more database tables. Each table includes:\n",
        "  - Table name and description\n",
        "  - Column names, data types, and column descriptions\n",
        "\n",
        "Assume that:\n",
        "- All columns are populated with valid and correctly typed data.\n",
        "- You are not required to write the SQL query or answer the question — only to determine whether it is possible to generate a complete query using the schema provided.\n",
        "\n",
        "Your task is to:\n",
        "1. Carefully analyze the natural language question to identify **all distinct information requirements** (e.g., filters, metrics, grouping, sorting).\n",
        "2. Review the table schemas and ensure that **every required data point** is represented by one or more columns in the schema.\n",
        "3. Consider relationships between tables only if they are explicitly defined or logically inferable from naming or descriptions.\n",
        "\n",
        "Only if **every part** of the question can be addressed with the schema provided, return:\n",
        "{{\"enough_information\": true}}\n",
        "\n",
        "If **any required element is missing** (e.g., age of users, movie ratings, like counts, timestamps, etc.), return:\n",
        "{{\"enough_information\": false}}\n",
        "\n",
        "Constraints:\n",
        "- You must evaluate the entire question in detail — partial answerability is not sufficient.\n",
        "- Do not assume access to external data, hidden metadata, or business logic beyond the schema.\n",
        "- Do not write or return SQL queries.\n",
        "- Your output must be only a single JSON object.\n",
        "\n",
        "Input format:\n",
        "Question: {natural_language_question}\n",
        "\n",
        "Table(s):\n",
        "{table_name_and_description}\n",
        "\n",
        "Example output:\n",
        "{{\"enough_information\": true}}\n",
        "\"\"\"\n",
        "\n",
        "  table_information = \"\"\n",
        "  for documents in state[\"table_documents\"]:\n",
        "    table_information += \"\\n\"+documents.page_content\n",
        "\n",
        "  print(table_information)\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_template(system_prompt)\n",
        "\n",
        "  structured_llm = llm.with_structured_output(QueryJsonOutput)\n",
        "\n",
        "  validation_chain = prompt | structured_llm\n",
        "\n",
        "  result = validation_chain.invoke({\"natural_language_question\" : state[\"question\"], \"table_name_and_description\": table_information})\n",
        "\n",
        "  print(result)\n",
        "  return {\"validation_result\" : result}"
      ],
      "metadata": {
        "id": "lTWwd3K7g98m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def send_tables(state:TableState):\n",
        "  tables = set()\n",
        "  for document in state[\"table_documents\"]:\n",
        "    tables.add(document.metadata[\"table_name\"])\n",
        "  return {\"resultant_tables\" : list(tables)}\n",
        "\n",
        "def not_possible_answer(state: TableState):\n",
        "  return {\"error_result\":\"result can not be found because It looks like you do not have enough data\"}"
      ],
      "metadata": {
        "id": "EC6fxh-XjeOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transition_by_validation(state: TableState):\n",
        "  if \"enough_information\" not in state[\"validation_result\"]:\n",
        "    raise Exception(\"llm is not returning correct json\")\n",
        "  if state[\"validation_result\"][\"enough_information\"] is True:\n",
        "    return \"answer_found\"\n",
        "  else:\n",
        "    if state[\"relevant_tables\"]<MAX_TABLE_SCHEMA:\n",
        "      return \"increase_relevence and reiletrate\"\n",
        "    else:\n",
        "      return \"answer_can_not_found\""
      ],
      "metadata": {
        "id": "OVx74iAo45Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def increase_relevance(state: TableState):\n",
        "  result = state[\"relevant_tables\"] + 2\n",
        "  return {\"relevant_tables\" : result}"
      ],
      "metadata": {
        "id": "8-LC9WRl96be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 1 -> send the question\n",
        "# step 2 -> get the resultant tables.. with default nearest value as 2\n",
        "# step 3 -> validate if the resultant tables are enough\n",
        "# step 4 -> if not increase the nearest neighbour by 2 and get the data and validate it again\n",
        "\n",
        "# step 5 -> get the column data with the default nearest neighbour value as 3\n",
        "# step 6 -> validate the resulttant\n",
        "\n",
        "\n",
        "table_graph_builder = StateGraph(TableState)\n",
        "# graph_builder = StateGraph(State)\n",
        "\n",
        "table_graph_builder.add_node(\"get_relevant_tables\", get_relevant_tables)\n",
        "table_graph_builder.add_node(\"validate_tables\", validate_relevant_tables)\n",
        "table_graph_builder.add_node(\"send_tables\", send_tables)\n",
        "table_graph_builder.add_node(\"not_possible_answer\", not_possible_answer)\n",
        "table_graph_builder.add_node(\"increase_relevance\", increase_relevance)\n",
        "\n",
        "table_graph_builder.add_edge(START, \"get_relevant_tables\")\n",
        "table_graph_builder.add_edge(\"get_relevant_tables\", \"validate_tables\")\n",
        "table_graph_builder.add_conditional_edges(\"validate_tables\", transition_by_validation, {\"increase_relevence and reiletrate\" : \"increase_relevance\", \"answer_found\" : \"send_tables\", \"answer_can_not_found\": \"not_possible_answer\"})\n",
        "table_graph_builder.add_edge(\"increase_relevance\", \"get_relevant_tables\")\n",
        "table_graph_builder.add_edge(\"send_tables\", END)\n",
        "table_graph_builder.add_edge(\"not_possible_answer\", END)\n",
        "\n",
        "table_gen_agent = table_graph_builder.compile()\n",
        "\n",
        "\n",
        "# 1 - get back and get more similar results\n",
        "# 2 - output the result\n",
        "# 3 - getting output is not possible\n",
        "\n",
        "# graph_builder.add_node(\"write_query\", write_query)\n",
        "# graph_builder.add_node(\"validate_query\", validate_query)\n",
        "# graph_builder.add_node(\"execute_query\", execute_query)\n",
        "# graph_builder.add_node(\"generate_answer\", generate_answer)\n",
        "\n",
        "# graph_builder.add_edge(START, \"write_query\")\n",
        "# graph_builder.add_edge(\"write_query\", \"validate_query\")\n",
        "\n",
        "# graph_builder.add_conditional_edges(\n",
        "#     \"validate_query\",\n",
        "#     transition_by_error,\n",
        "#     {\"valid_query\":\"execute_query\",\n",
        "#      \"not_valid_query\":\"write_query\"}\n",
        "# )\n",
        "\n",
        "# graph_builder.add_edge(\"execute_query\", \"generate_answer\")\n",
        "# graph_builder.add_edge(\"generate_answer\", END)\n",
        "\n",
        "# graph = graph_builder.compile()\n",
        "# sql_agent"
      ],
      "metadata": {
        "id": "NKbclJgsiI5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Save graph to file\n",
        "graph_path = \"_table_gen_agent_graph.png\"\n",
        "with open(graph_path, \"wb\") as f:\n",
        "    f.write(table_gen_agent.get_graph().draw_mermaid_png())\n",
        "\n",
        "# Display the saved image (clean output)\n",
        "display(Image(filename=graph_path))"
      ],
      "metadata": {
        "id": "-bdsitJ368XS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in table_gen_agent.stream(\n",
        "    {\"question\": \"tell me 5 most likeable movies by our young users?\", \"relevant_tables\": 1, \"vectorstore\": vector_store}, stream_mode=\"updates\"\n",
        "):\n",
        "    print(step)"
      ],
      "metadata": {
        "id": "QWPWl9IS7CLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Table Generation Workflow is done and the output is amazing I am getting all the related tables.. as you can see in resultant_tables"
      ],
      "metadata": {
        "id": "D1jFOsRLiDCd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XAAWtzbWiT0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Started Working on Related Column Generation Workflow"
      ],
      "metadata": {
        "id": "9kzbKNG6iUMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ColumnState(TypedDict):\n",
        "    question : str # user query\n",
        "    relevant_columns : int  # no of relevant columns\n",
        "    column_documents : list # columns documents which are going to fetch\n",
        "    validation_result : dict # validation result\n",
        "    input_tables : list # list of columns to get the documents\n",
        "    result : str # final output\n",
        "    error_result : str # if the relevant tables can not found.\n",
        "    vectorstore : FAISS"
      ],
      "metadata": {
        "id": "mZggnPio-9TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relevant_columns(state: ColumnState):\n",
        "  vector_store = state[\"vectorstore\"]\n",
        "  res = vector_store.similarity_search(\n",
        "    state[\"question\"],\n",
        "    k=state[\"relevant_columns\"],\n",
        "    filter={\"source\": \"column_schema\", \"table_name\": {\"$in\": state[\"input_tables\"]}},\n",
        "  )\n",
        "\n",
        "  return {\"column_documents\": res}"
      ],
      "metadata": {
        "id": "aiCdrhrL-9We"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_relevant_tables_and_columns(state : ColumnState):\n",
        "  system_prompt = \"\"\"\n",
        "You are a helpful assistant that evaluates whether a given set of database tables contains enough schema information to generate a valid SQL query that answers a natural language question **in full**.\n",
        "\n",
        "You will be provided with:\n",
        "- A natural language question.\n",
        "- One or more database tables. Each table includes:\n",
        "  - Table name and description\n",
        "  - Column names, data types, and column descriptions\n",
        "\n",
        "Assume that:\n",
        "- All columns are populated with valid and correctly typed data.\n",
        "- You are not required to write the SQL query or answer the question — only to determine whether it is possible to generate a complete query using the schema provided.\n",
        "\n",
        "Your task is to:\n",
        "1. Carefully analyze the natural language question to identify **all distinct information requirements** (e.g., filters, metrics, grouping, sorting).\n",
        "2. Review the table schemas and ensure that **every required data point** is represented by one or more columns in the schema.\n",
        "3. Consider relationships between tables only if they are explicitly defined or logically inferable from naming or descriptions.\n",
        "\n",
        "Only if **every part** of the question can be addressed with the schema provided, return:\n",
        "{{\"enough_information\": true}}\n",
        "\n",
        "If **any required element is missing** (e.g., age of users, movie ratings, like counts, timestamps, etc.), return:\n",
        "{{\"enough_information\": false}}\n",
        "\n",
        "Constraints:\n",
        "- You must evaluate the entire question in detail — partial answerability is not sufficient.\n",
        "- Do not assume access to external data, hidden metadata, or business logic beyond the schema.\n",
        "- Do not write or return SQL queries.\n",
        "- Your output must be only a single JSON object.\n",
        "\n",
        "Input format:\n",
        "Question: {natural_language_question}\n",
        "\n",
        "Table(s):\n",
        "{table_name_and_description}\n",
        "\n",
        "Example output:\n",
        "{{\"enough_information\": true}}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "  column_documents = state[\"column_documents\"]\n",
        "\n",
        "  table_column_documents = {}\n",
        "  for documents in column_documents:\n",
        "    if documents.metadata[\"table_name\"] not in table_column_documents:\n",
        "      table_column_documents[documents.metadata[\"table_name\"]] = \"Table Name: \"+documents.metadata[\"table_name\"]+\"\\n\"\n",
        "      table_column_documents[documents.metadata[\"table_name\"]] += \"Description: \"+documents.metadata[\"table_description\"]\n",
        "      table_column_documents[documents.metadata[\"table_name\"]] += \"\\n\\n\"\n",
        "      table_column_documents[documents.metadata[\"table_name\"]] += \"Columns:\\n\"\n",
        "    table_column_documents[documents.metadata[\"table_name\"]] += documents.page_content\n",
        "\n",
        "  table_column_information = \"\"\n",
        "  for tables in table_column_documents:\n",
        "    table_column_information += \"\\n\"+table_column_documents[tables]\n",
        "\n",
        "  print(table_column_information)\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_template(system_prompt)\n",
        "\n",
        "  structured_llm = llm.with_structured_output(QueryJsonOutput)\n",
        "\n",
        "  validation_chain = prompt | structured_llm\n",
        "\n",
        "  result = validation_chain.invoke({\"natural_language_question\" : state[\"question\"], \"table_name_and_description\": table_column_information})\n",
        "\n",
        "  return {\"validation_result\" : result}"
      ],
      "metadata": {
        "id": "1qBOoVjnsXVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transition_by_column_validation(state: ColumnState):\n",
        "  if \"enough_information\" not in state[\"validation_result\"]:\n",
        "    raise Exception(\"llm is not returning correct json\")\n",
        "  if state[\"validation_result\"][\"enough_information\"] is True:\n",
        "    return \"answer_found\"\n",
        "  else:\n",
        "    if state[\"relevant_columns\"]<MAX_COLUMN_SCHEMA:\n",
        "      return \"increase_relevence and reiletrate\"\n",
        "    else:\n",
        "      return \"answer_can_not_found\""
      ],
      "metadata": {
        "id": "Qn1Hb9LUw7U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def increase_column_relevance(state: ColumnState):\n",
        "  result = state[\"relevant_columns\"] + 2\n",
        "  return {\"relevant_columns\" : result}\n",
        "\n",
        "def send_tables_information_as_string(state : ColumnState):\n",
        "  column_documents = state[\"column_documents\"]\n",
        "\n",
        "  table_column_documents = {}\n",
        "  for documents in column_documents:\n",
        "    if documents.metadata[\"table_name\"] not in table_column_documents:\n",
        "      table_column_documents[documents.metadata[\"table_name\"]] = \"Table Name: \"+documents.metadata[\"table_name\"]+\"\\n\"\n",
        "      table_column_documents[documents.metadata[\"table_name\"]] += \"Description: \"+documents.metadata[\"table_description\"]\n",
        "      table_column_documents[documents.metadata[\"table_name\"]] += \"\\n\\n\"\n",
        "      table_column_documents[documents.metadata[\"table_name\"]] += \"Columns:\\n\"\n",
        "    table_column_documents[documents.metadata[\"table_name\"]] += documents.page_content\n",
        "\n",
        "  table_column_information = \"\"\n",
        "  for tables in table_column_documents:\n",
        "    table_column_information += \"\\n\"+table_column_documents[tables]\n",
        "\n",
        "  return {\"result\": table_column_information}"
      ],
      "metadata": {
        "id": "UPmc7PCaxgJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_builder = StateGraph(ColumnState)\n",
        "graph_builder.add_node(\"get_relevant_columns\", get_relevant_columns)\n",
        "graph_builder.add_node(\"validate_relevant_tables_and_columns\", validate_relevant_tables_and_columns)\n",
        "graph_builder.add_node(\"increase_relevance\", increase_column_relevance)\n",
        "graph_builder.add_node(\"send_tables_information_as_string\", send_tables_information_as_string)\n",
        "graph_builder.add_node(\"not_possible_answer\", not_possible_answer)\n",
        "\n",
        "graph_builder.add_edge(START, \"get_relevant_columns\")\n",
        "graph_builder.add_edge(\"get_relevant_columns\", \"validate_relevant_tables_and_columns\")\n",
        "graph_builder.add_conditional_edges(\"validate_relevant_tables_and_columns\", transition_by_column_validation, {\"increase_relevence and reiletrate\" : \"increase_relevance\", \"answer_found\" : \"send_tables_information_as_string\", \"answer_can_not_found\": \"not_possible_answer\"})\n",
        "graph_builder.add_edge(\"increase_relevance\", \"get_relevant_columns\")\n",
        "graph_builder.add_edge(\"send_tables_information_as_string\", END)\n",
        "graph_builder.add_edge(\"not_possible_answer\", END)\n",
        "\n",
        "\n",
        "column_gen_agent = graph_builder.compile()"
      ],
      "metadata": {
        "id": "UvGtAIUK7Xpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Save graph to file\n",
        "graph_path = \"_column_gen_agent_graph.png\"\n",
        "with open(graph_path, \"wb\") as f:\n",
        "    f.write(column_gen_agent.get_graph().draw_mermaid_png())\n",
        "\n",
        "# Display the saved image (clean output)\n",
        "display(Image(filename=graph_path))"
      ],
      "metadata": {
        "id": "EiXKwQQhplTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in column_gen_agent.stream(\n",
        "    {\"question\": \"top 5 ranked movies?\", \"relevant_columns\": 4, \"input_tables\" : ['ratings', 'movies'], \"vectorstore\": vector_store}, stream_mode=\"updates\"\n",
        "):\n",
        "    print(step)"
      ],
      "metadata": {
        "id": "2DFvKCO4pex7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can get the output in any fomat but chosen simple string as our next workflow will be needing the output in the simple plain text"
      ],
      "metadata": {
        "id": "TXhOcgviim-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plan of action: For getting answers from a query"
      ],
      "metadata": {
        "id": "Um57rlBNtyOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user query ask ->\n",
        "\n",
        "# Node-1 -> Query generation Agent -> take the llm , table description and prompt and generate a sqlite query\n",
        "# Node-2 -> Validate the query -> run the query in sqlite and checks if it gives any error or not if yes return the error and move for refinement\n",
        "# if no move to llm to generate the output\n",
        "# Node-3 -> Refine the query -> take the error , table description and prompt and do the query generation again and move back to agent-2\n",
        "\n",
        "# After getting the output\n",
        "# Node-4 -> Geneate the final output and return it using a table.\n"
      ],
      "metadata": {
        "id": "d6JRcJ_Dw_H6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creation of an Sql Agent Begins -> query generator validator and executor"
      ],
      "metadata": {
        "id": "X-uujx8Fi8AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class Error(TypedDict):\n",
        "    iserror : bool\n",
        "    error : str\n",
        "\n",
        "class SqlState(TypedDict):\n",
        "    question: str\n",
        "    query: str\n",
        "    result: str\n",
        "    answer: str\n",
        "    top_k: int\n",
        "    table_schema : str\n",
        "    dialect : str\n",
        "    error : Error\n",
        "\n",
        "class QueryOutput(TypedDict):\n",
        "    \"\"\"Generated SQL query.\"\"\"\n",
        "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
        "\n",
        "def write_query(state: SqlState):\n",
        "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
        "    if 'error' in state and 'iserror' in state['error'] and state['error']['iserror']:\n",
        "\n",
        "      system_error_prompt = \"\"\"\n",
        "          You are an expert SQL query assistant. Your task is to analyze a provided SQL query, along with a natural language question, error description, and table schema (with column information). You must identify issues in the SQL query and generate a corrected, syntactically valid SQL query that fulfills the user’s intent based on the given SQL dialect. Follow these strict instructions:\n",
        "\n",
        "          What You Receive as Input:\n",
        "          - A natural language question representing the user's intent.\n",
        "          - A raw SQL query generated for that question.\n",
        "          - An error message (if any) generated during execution of the query.\n",
        "          - A schema, which includes table names and the list of valid columns for each table.\n",
        "          - The required SQL dialect (e.g., PostgreSQL, MySQL, SQLite, etc.).\n",
        "          - (Optional) A number of examples the user wants in the result.\n",
        "\n",
        "          What You Must Do:\n",
        "          1. Understand the Intent:\n",
        "            - Parse the natural language question to determine the user’s actual intent and what data they are trying to retrieve.\n",
        "\n",
        "          2. Validate the Original Query:\n",
        "            - Compare the SQL query against the schema.\n",
        "            - Identify misuse of columns, incorrect table joins, or syntax errors.\n",
        "            - Use the provided error message to help locate the issue (e.g., missing columns, ambiguous names, invalid syntax, unsupported features).\n",
        "\n",
        "          3. Correct the Query:\n",
        "            - Rewrite the SQL query to fix any issues while preserving the user’s intent.\n",
        "            - Ensure the query is syntactically correct for the specified SQL dialect.\n",
        "\n",
        "          4. Apply Output Constraints:\n",
        "            - Only use columns and tables explicitly defined in the schema. Do not use any undefined columns.\n",
        "            - Be aware of which columns belong to which tables to avoid ambiguous or invalid references.\n",
        "            - If the user specifies a number of examples (top K results), apply an appropriate LIMIT K clause.\n",
        "            - Sort the results using meaningful columns (e.g., created_at, score, or other relevance indicators) to provide the most informative and relevant answers.\n",
        "            - Ensure the query is well-structured and readable.\n",
        "\n",
        "          Rules to Follow:\n",
        "          - Always use only the columns listed in the schema.\n",
        "          - Be aware of which columns belong to which tables to avoid invalid references.\n",
        "          - Choose sorting columns that provide semantic value or align with the user's question.\n",
        "          - Follow the syntax and functions specific to the provided SQL dialect.\n",
        "          - If LIMIT is not specified and no number of examples is given, default to LIMIT 10.\n",
        "          - Use fully qualified column names (table.column) where needed for clarity and correctness.\n",
        "\n",
        "          Output Format:\n",
        "          Your response should include only the final corrected SQL query, formatted properly. Do not include explanations or extra text unless specifically asked for.\n",
        "      \"\"\"\n",
        "\n",
        "      user_prompt = \"\"\"Input Information:\n",
        "          - Natural language question: {question}\n",
        "          - Original SQL query: {original_query}\n",
        "          - Error message (if any): {error_message}\n",
        "          - SQL dialect: {dialect}\n",
        "          - Number of examples requested (if any): {k_examples}\n",
        "          - Schema (tables and columns): {schema}\n",
        "      \"\"\"\n",
        "\n",
        "      error_prompt_template = ChatPromptTemplate(\n",
        "          [(\"system\", system_error_prompt), (\"user\", user_prompt)]\n",
        "      )\n",
        "\n",
        "      prompt = error_prompt_template.invoke(\n",
        "          {\n",
        "              \"error_message\" : state['error']['error'],\n",
        "              \"original_query\" : state['query'],\n",
        "              \"dialect\": state[\"dialect\"],\n",
        "              \"k_examples\": str(state[\"top_k\"]),\n",
        "              \"schema\": state[\"table_schema\"],\n",
        "              \"question\": state[\"question\"],\n",
        "          }\n",
        "      )\n",
        "\n",
        "    else:\n",
        "\n",
        "      system_message = \"\"\"\n",
        "        Given an input question, create a syntactically correct {dialect} query to\n",
        "        run to help find the answer. Unless the user specifies in his question a\n",
        "        specific number of examples they wish to obtain, ensure the query limits the output to\n",
        "        no more than {top_k} entries. You can order the results by a relevant column to\n",
        "        return the most interesting examples in the database.\n",
        "\n",
        "        Never query for all the columns from a specific table, only ask for a the\n",
        "        few relevant columns given the question.\n",
        "\n",
        "        Pay attention to use only the column names that you can see in the schema\n",
        "        description. Be careful to not query for columns that do not exist. Also,\n",
        "        pay attention to which column is in which table.\n",
        "\n",
        "        Only use the following tables:\n",
        "        {table_info}\n",
        "      \"\"\"\n",
        "\n",
        "      user_prompt = \"Question: {input}\"\n",
        "\n",
        "      query_prompt_template = ChatPromptTemplate(\n",
        "          [(\"system\", system_message), (\"user\", user_prompt)]\n",
        "      )\n",
        "\n",
        "      prompt = query_prompt_template.invoke(\n",
        "          {\n",
        "              \"dialect\": state[\"dialect\"],\n",
        "              \"top_k\": str(state[\"top_k\"]),\n",
        "              \"table_info\": state[\"table_schema\"],\n",
        "              \"input\": state[\"question\"],\n",
        "          }\n",
        "      )\n",
        "    structured_llm = llm.with_structured_output(QueryOutput)\n",
        "    result = structured_llm.invoke(prompt)\n",
        "    return {\"query\": result[\"query\"]}"
      ],
      "metadata": {
        "id": "xvcn7pWJ6dV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
        "\n",
        "def execute_query(state: SqlState):\n",
        "    \"\"\"Execute SQL query.\"\"\"\n",
        "    conn = sqlite3.connect('real_database.db')\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(state[\"query\"])\n",
        "    rows = cursor.fetchall()\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    return {\"result\": rows}\n",
        "\n",
        "    # execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
        "    # return {\"result\": execute_query_tool.invoke(state[\"query\"])}"
      ],
      "metadata": {
        "id": "tkE-ojda81Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_query(state: SqlState):\n",
        "  \"\"\"Validate Sql Query\"\"\"\n",
        "  conn = sqlite3.connect('dummy_database.db')\n",
        "  cursor = conn.cursor()\n",
        "  try:\n",
        "    cursor.execute(state[\"query\"])\n",
        "    rows = cursor.fetchall()\n",
        "    return {\"error\" : {\"iserror\": False, \"error\": ''}}\n",
        "  except Exception as e:\n",
        "    return {\"error\" : {\"iserror\": True, \"error\": str(e)}}\n",
        "  finally:\n",
        "    cursor.close()\n",
        "    conn.close()"
      ],
      "metadata": {
        "id": "4ZThUkW6EIGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "execute_query({\"query\": \"SELECT count(DISTINCT movie_id) FROM ratings LIMIT 10\"})"
      ],
      "metadata": {
        "id": "NoTOI4kl-a-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(state: SqlState):\n",
        "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
        "    prompt = (\n",
        "        \"You are a data interpretation assistant.\\n\\n\"\n",
        "        \"Answer the user's question clearly and directly using only the provided data.\\n\\n\"\n",
        "        \"If you cannot find the answer from the provided data, simply state:\\n\"\n",
        "        \"\\\"I cannot provide the answer using the provided data.\\\"\\n\"\n",
        "        \"Do not give any explanation or reasoning.\\n\\n\"\n",
        "        \"If you can find the answer, do not mention SQL queries or SQL results in your response. Instead, provide:\\n\"\n",
        "        \"- A clear, final answer that directly addresses the user's question.\\n\"\n",
        "        \"- A brief explanation of how the answer was derived, including what in the data supports it (but not the query used).\\n\\n\"\n",
        "        \"Keep your response focused, factual, and based solely on the provided information.\"\n",
        "        f\"Question: {state['question']}\\n\"\n",
        "        f\"SQL Query: {state['query']}\\n\"\n",
        "        f\"SQL Result: {state['result']}\"\n",
        "    )\n",
        "    print(\"query : \", state['query'])\n",
        "    print(\"result : \", state['result'])\n",
        "    response = llm.invoke(prompt)\n",
        "    return {\"answer\": response.content}"
      ],
      "metadata": {
        "id": "uof5nzQd-f4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transition_by_error(state: SqlState):\n",
        "  if state[\"error\"][\"iserror\"] is True:\n",
        "    return \"not_valid_query\"\n",
        "  else:\n",
        "    return \"valid_query\""
      ],
      "metadata": {
        "id": "z4D1f2VsKhad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import START,END, StateGraph\n",
        "\n",
        "\n",
        "sql_graph_builder = StateGraph(SqlState)\n",
        "\n",
        "sql_graph_builder.add_node(\"write_query\", write_query)\n",
        "sql_graph_builder.add_node(\"validate_query\", validate_query)\n",
        "sql_graph_builder.add_node(\"execute_query\", execute_query)\n",
        "sql_graph_builder.add_node(\"generate_answer\", generate_answer)\n",
        "\n",
        "sql_graph_builder.add_edge(START, \"write_query\")\n",
        "sql_graph_builder.add_edge(\"write_query\", \"validate_query\")\n",
        "\n",
        "sql_graph_builder.add_conditional_edges(\n",
        "    \"validate_query\",\n",
        "    transition_by_error,\n",
        "    {\"valid_query\":\"execute_query\",\n",
        "     \"not_valid_query\":\"write_query\"}\n",
        ")\n",
        "\n",
        "sql_graph_builder.add_edge(\"execute_query\", \"generate_answer\")\n",
        "sql_graph_builder.add_edge(\"generate_answer\", END)\n",
        "\n",
        "sql_agent = sql_graph_builder.compile()\n",
        "# sql_agent"
      ],
      "metadata": {
        "id": "KlfQXOYD-uqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(sql_agent.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "T34C8JvD-5Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dialect():\n",
        "  conn = sqlite3.connect(\":memory:\")\n",
        "  # Create a cursor to interact with the database\n",
        "  cursor = conn.cursor()\n",
        "  # Get the SQLite version\n",
        "  cursor.execute(\"select sqlite_version();\")\n",
        "  version = cursor.fetchone()[0]\n",
        "  return 'sqlite : '+version"
      ],
      "metadata": {
        "id": "Mu4vzWv68G3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = '\\nTable Name: movies\\nDescription: This table includes metadata related to the movies.\\n\\nColumns:\\n- movie_id (INTEGER): Unique movie identifier- movie_title (TEXT): Title of the movie (with release year)\\nTable Name: ratings\\nDescription: This table captures the ratings provided by users for specific movies.\\n\\nColumns:\\n- user_rating (INTEGER): Rating from 1 to 5 (whole stars only)- movie_id (INTEGER): Foreign key referring to movies table'\n",
        "for step in sql_agent.stream(\n",
        "    {\"question\": \"top 5 ranked movies?\",\"dialect\":get_dialect(),\"top_k\":5,\"table_schema\":sc}, stream_mode=\"updates\"\n",
        "):\n",
        "    print(step)"
      ],
      "metadata": {
        "id": "QhRXiJGEjizU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for step in sql_agent.stream(\n",
        "#     {\"question\": \"Backdraft released in?\",\"dialect\":get_dialect(),\"top_k\":5,\"table_schema\":sc}, stream_mode=\"updates\"\n",
        "# ):\n",
        "#     print(step)"
      ],
      "metadata": {
        "id": "RuWaBTmz-7j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for step in sql_agent.stream(\n",
        "#     {\"question\": \"how many users are unsatisfied with the movies?\",\"dialect\":get_dialect(),\"top_k\":5,\"table_schema\":sc}, stream_mode=\"updates\"\n",
        "# ):\n",
        "#     print(step)"
      ],
      "metadata": {
        "id": "KULW4tbPTytp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for step in sql_agent.stream(\n",
        "#     {\"question\": \"how many users are satisfied with the movies?\",\"dialect\":get_dialect(),\"top_k\":5,\"table_schema\":sc}, stream_mode=\"updates\"\n",
        "# ):\n",
        "#     print(step)"
      ],
      "metadata": {
        "id": "M6U-2IlbT80O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for step in sql_agent.stream(\n",
        "#     {\"question\": \"tell me 5 most likeable movies by our old users?\",\"dialect\":get_dialect(),\"top_k\":5,\"table_schema\":sc}, stream_mode=\"updates\"\n",
        "# ):\n",
        "#     print(step)"
      ],
      "metadata": {
        "id": "3pBMLRN5WjbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for step in sql_agent.stream(\n",
        "#     {\"question\": \"tell me 5 most likeable movies by our young users?\",\"dialect\":get_dialect(),\"top_k\":5,\"table_schema\":sc}, stream_mode=\"updates\"\n",
        "# ):\n",
        "#     print(step)"
      ],
      "metadata": {
        "id": "IWcq83CbW2Xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for step in sql_agent.stream(\n",
        "#     {\"question\": \"tell me 5 most likeable movies by our mid age users?\",\"dialect\":get_dialect(),\"top_k\":5,\"table_schema\":sc}, stream_mode=\"updates\"\n",
        "# ):\n",
        "#     print(step)"
      ],
      "metadata": {
        "id": "73WyV45wVnul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for step in sql_agent.stream(\n",
        "#     {\"question\": \"top 5 ranked movies?\",\"dialect\":get_dialect(),\"top_k\":5,\"table_schema\":sc}, stream_mode=\"updates\"\n",
        "# ):\n",
        "#     print(step)"
      ],
      "metadata": {
        "id": "kA4xruJOXHzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# res = sql_agent.invoke(\n",
        "#     {\"question\": \"top 5 ranked movies?\",\"dialect\":get_dialect(),\"top_k\":5,\"table_schema\":sc}\n",
        "# )\n"
      ],
      "metadata": {
        "id": "6thu9CJVAa6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combined them together to create a multi-agentic workflow"
      ],
      "metadata": {
        "id": "Ihcx9ucskKAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    question : str # user query\n",
        "    fetched_tables : list\n",
        "    table_information : str\n",
        "    init_relevant_tables: int\n",
        "    init_relevant_columns : int\n",
        "    vectorstore: FAISS\n",
        "    relevant_columns : list\n",
        "    dialect: str\n",
        "    top_k : int\n",
        "    sql_agent_output : str\n",
        "    final_output : str\n",
        "    error : str\n",
        "    iserror : bool"
      ],
      "metadata": {
        "id": "zTooI5VOrDCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def invoke_get_table_agaent(state : State):\n",
        "  print(\"passed_values\", {\"question\": state[\"question\"], \"relevant_tables\": state[\"init_relevant_tables\"], \"vectorstore\": state[\"vectorstore\"]})\n",
        "  res = table_gen_agent.invoke({\"question\": state[\"question\"], \"relevant_tables\": state[\"init_relevant_tables\"], \"vectorstore\": state[\"vectorstore\"]})\n",
        "  if 'error_result' in res:\n",
        "    return {'error' : res['error_result'], 'iserror' : True}\n",
        "  final_result = res['resultant_tables']\n",
        "  return {'fetched_tables' : final_result}"
      ],
      "metadata": {
        "id": "sIcKDKT5EJSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def invoke_get_column_agent(state: State):\n",
        "  print({\"question\": state[\"question\"], \"relevant_columns\": state[\"init_relevant_columns\"],\"input_tables\" : state[\"fetched_tables\"], \"vectorstore\": state[\"vectorstore\"]})\n",
        "  res = column_gen_agent.invoke({\"question\": state[\"question\"], \"relevant_columns\": state[\"init_relevant_columns\"],\"input_tables\" : state[\"fetched_tables\"], \"vectorstore\": state[\"vectorstore\"]})\n",
        "  if 'error_result' in res:\n",
        "    return {'error' : res['error_result'], 'iserror' : True}\n",
        "  final_result = res['result']\n",
        "  return {'table_information' : final_result}"
      ],
      "metadata": {
        "id": "qOavSWFmvcAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_final_output(state: State):\n",
        "  res = sql_agent.invoke({\"question\": state[\"question\"],\"dialect\": state[\"dialect\"], \"top_k\":state[\"top_k\"], \"table_schema\": state[\"table_information\"]})\n",
        "  final_result = res['answer']\n",
        "  return {'sql_agent_output': final_result}"
      ],
      "metadata": {
        "id": "5LSFQaQWwYvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_final_answer(state: State):\n",
        "  if \"iserror\" in state and state[\"iserror\"]:\n",
        "    return {'final_output' : state['error']}\n",
        "  else:\n",
        "    return {'final_output' : state['sql_agent_output']}"
      ],
      "metadata": {
        "id": "JDEb1p1C19Mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transition_state(state: State):\n",
        "  if \"iserror\" in state and state[\"iserror\"]:\n",
        "    return \"generate_output\"\n",
        "  else:\n",
        "    return \"next_step\""
      ],
      "metadata": {
        "id": "aSyUH5IK2iXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_agent_builder = StateGraph(State)\n",
        "\n",
        "combined_agent_builder.add_node(\"table_agent\", invoke_get_table_agaent)\n",
        "combined_agent_builder.add_node(\"column_agent\", invoke_get_column_agent)\n",
        "combined_agent_builder.add_node(\"sql_agent\", get_final_output)\n",
        "combined_agent_builder.add_node(\"generate_final_answer\", generate_final_answer)\n",
        "\n",
        "combined_agent_builder.add_edge(START, \"table_agent\")\n",
        "combined_agent_builder.add_conditional_edges(\n",
        "    \"table_agent\",\n",
        "    transition_state,\n",
        "    {\"generate_output\":\"generate_final_answer\",\n",
        "     \"next_step\":\"column_agent\"}\n",
        ")\n",
        "combined_agent_builder.add_conditional_edges(\n",
        "    \"column_agent\",\n",
        "    transition_state,\n",
        "    {\"generate_output\":\"generate_final_answer\",\n",
        "     \"next_step\":\"sql_agent\"}\n",
        ")\n",
        "combined_agent_builder.add_edge(\"sql_agent\", \"generate_final_answer\")\n",
        "combined_agent_builder.add_edge(\"generate_final_answer\", END)\n",
        "\n",
        "combined_agent = combined_agent_builder.compile()"
      ],
      "metadata": {
        "id": "fgNQOIK1yDVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Save graph to file\n",
        "graph_path = \"_table_gen_agent_graph.png\"\n",
        "with open(graph_path, \"wb\") as f:\n",
        "    f.write(table_gen_agent.get_graph().draw_mermaid_png())\n",
        "\n",
        "# Display the saved image (clean output)\n",
        "display(Image(filename=graph_path))"
      ],
      "metadata": {
        "id": "e0pqiSeN0REm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Save graph to file\n",
        "graph_path = \"_column_gen_agent_graph.png\"\n",
        "with open(graph_path, \"wb\") as f:\n",
        "    f.write(column_gen_agent.get_graph().draw_mermaid_png())\n",
        "\n",
        "# Display the saved image (clean output)\n",
        "display(Image(filename=graph_path))"
      ],
      "metadata": {
        "id": "USy7kZqrp04K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Save graph to file\n",
        "graph_path = \"_sql_agent_graph.png\"\n",
        "with open(graph_path, \"wb\") as f:\n",
        "    f.write(sql_agent.get_graph().draw_mermaid_png())\n",
        "\n",
        "# Display the saved image (clean output)\n",
        "display(Image(filename=graph_path))"
      ],
      "metadata": {
        "id": "ZZ7IsZv-p2dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "# Save graph to file\n",
        "graph_path = \"_combined_agent_graph.png\"\n",
        "with open(graph_path, \"wb\") as f:\n",
        "    f.write(combined_agent.get_graph().draw_mermaid_png())\n",
        "\n",
        "# Display the saved image (clean output)\n",
        "display(Image(filename=graph_path))"
      ],
      "metadata": {
        "id": "7mRV22Wnp_Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for step in table_gen_agent.stream(\n",
        "#     {'question': 'top 5 ranked movies?', 'relevant_tables': 1, 'vectorstore': vector_store}, stream_mode=\"updates\"\n",
        "# ):\n",
        "#     print(step)"
      ],
      "metadata": {
        "id": "BnYykO5z-DLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for step in column_gen_agent.stream({\"question\": \"top 5 ranked movies??\", \"relevant_columns\": 1, \"input_tables\" : ['users', 'ratings', 'movies'], \"vectorstore\": vector_store}, stream_mode=\"updates\"):\n",
        "# column_gen_agent.invoke({\"question\": \"top 5 ranked movies?\", \"relevant_columns\": 2, \"input_tables\" : ['users', 'ratings', 'movies'], \"vectorstore\": vector_store})\n",
        "    # print(step)"
      ],
      "metadata": {
        "id": "lxwecNETEI3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# column_gen_agent.invoke({\"question\": \"top 5 ranked movies?\", \"relevant_columns\": 3, \"input_tables\" : ['users', 'ratings', 'movies'], \"vectorstore\": vector_store})\n"
      ],
      "metadata": {
        "id": "_KfZMcSTDtmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_agent.invoke({\"question\": \"Backdraft released in?\", \"dialect\":get_dialect(), \"top_k\":5, \"vectorstore\":vector_store, \"init_relevant_tables\": 2, \"init_relevant_columns\": 4})"
      ],
      "metadata": {
        "id": "VjSb4PhXzn8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZVC17woerO6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wY-PZGFxrPma"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}